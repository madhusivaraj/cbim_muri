INFO:root:Namespace(aggregation='average', batch_size=256, debug=False, device=device(type='cpu'), dropout=0.1, epochs=50, hidden_size=128, in_features=17, kernel_size=3, log_dir='exps/logs', lr=0.0001, model='GRU', num_channels=[64, 64, 128], num_classes=2, num_layers=2, num_workers=4, print_freq=5, root='data', save_dir='exps/chpts/GRU_layers2_stride5_average_lr0.0001', seed=14, start_epoch=0, tb_dir='exps/tb/GRU_layers2_stride5_average_lr0.0001', temp_stride=5)
INFO:root:GRU(
  (rnn): GRU(17, 128, num_layers=2, batch_first=True)
  (fc): Linear(in_features=128, out_features=2, bias=True)
  (avg_pool): AdaptiveAvgPool1d(output_size=1)
  (max_pool): AdaptiveMaxPool1d(output_size=1)
)
INFO:root:=> Loading 4792 samples for train
INFO:root:=> Loading 626 samples for val
INFO:root:=> Loading 1166 samples for test
INFO:root:Namespace(aggregation='average', batch_size=256, debug=False, device=device(type='cpu'), dropout=0.1, epochs=20, hidden_size=128, in_features=17, kernel_size=3, log_dir='exps/logs', lr=0.0001, model='GRU', num_channels=[64, 64, 128], num_classes=2, num_layers=2, num_workers=4, print_freq=5, root='data', save_dir='exps/chpts/GRU_layers2_stride5_average_lr0.0001', seed=14, start_epoch=0, tb_dir='exps/tb/GRU_layers2_stride5_average_lr0.0001', temp_stride=5)
INFO:root:GRU(
  (rnn): GRU(17, 128, num_layers=2, batch_first=True)
  (fc): Linear(in_features=128, out_features=2, bias=True)
  (avg_pool): AdaptiveAvgPool1d(output_size=1)
  (max_pool): AdaptiveMaxPool1d(output_size=1)
)
INFO:root:=> Loading 4792 samples for train
INFO:root:=> Loading 626 samples for val
INFO:root:=> Loading 1166 samples for test
INFO:root:TRAIN | Epoch: [0/20] | Loss: 0.6887 | AP: 41.23 | TP:90.84, FP:142.04, FN:8.81, TN:11.54 | ACC: 40.42
INFO:root:VAL   | Epoch: [0/20] | Loss: 0.6943 | AP: 30.53 | TP:129.0, FP:184.0, FN:0.0, TN:0.0 | ACC: 41.21
INFO:root:=> AP improved (30.53) improved at epoch 0 | saving best model!
INFO:root:TRAIN | Epoch: [1/20] | Loss: 0.6819 | AP: 44.74 | TP:99.46, FP:152.94, FN:0.32, TN:0.52 | ACC: 39.44
INFO:root:VAL   | Epoch: [1/20] | Loss: 0.6965 | AP: 31.91 | TP:128.5, FP:181.5, FN:0.5, TN:2.5 | ACC: 41.85
INFO:root:=> AP improved (31.91) improved at epoch 1 | saving best model!
INFO:root:TRAIN | Epoch: [2/20] | Loss: 0.6787 | AP: 46.92 | TP:96.21, FP:144.78, FN:3.49, TN:8.75 | ACC: 41.42
INFO:root:VAL   | Epoch: [2/20] | Loss: 0.6997 | AP: 32.83 | TP:118.0, FP:166.5, FN:11.0, TN:17.5 | ACC: 43.29
INFO:root:=> AP improved (32.83) improved at epoch 2 | saving best model!
INFO:root:TRAIN | Epoch: [3/20] | Loss: 0.6759 | AP: 48.21 | TP:92.03, FP:132.21, FN:7.60, TN:21.40 | ACC: 44.76
INFO:root:VAL   | Epoch: [3/20] | Loss: 0.7028 | AP: 33.52 | TP:111.0, FP:163.0, FN:18.0, TN:21.0 | ACC: 42.17
INFO:root:=> AP improved (33.52) improved at epoch 3 | saving best model!
INFO:root:TRAIN | Epoch: [4/20] | Loss: 0.6745 | AP: 48.30 | TP:90.51, FP:130.56, FN:9.19, TN:22.97 | ACC: 44.78
INFO:root:VAL   | Epoch: [4/20] | Loss: 0.7040 | AP: 33.83 | TP:111.5, FP:163.0, FN:17.5, TN:21.0 | ACC: 42.33
INFO:root:=> AP improved (33.83) improved at epoch 4 | saving best model!
INFO:root:TRAIN | Epoch: [5/20] | Loss: 0.6718 | AP: 49.21 | TP:88.47, FP:123.64, FN:11.20, TN:29.92 | ACC: 46.77
INFO:root:VAL   | Epoch: [5/20] | Loss: 0.7069 | AP: 34.62 | TP:102.5, FP:155.5, FN:26.5, TN:28.5 | ACC: 41.85
INFO:root:=> AP improved (34.62) improved at epoch 5 | saving best model!
INFO:root:TRAIN | Epoch: [6/20] | Loss: 0.6706 | AP: 49.52 | TP:85.84, FP:118.39, FN:13.95, TN:35.06 | ACC: 47.64
INFO:root:VAL   | Epoch: [6/20] | Loss: 0.7086 | AP: 35.06 | TP:107.0, FP:158.5, FN:22.0, TN:25.5 | ACC: 42.33
INFO:root:=> AP improved (35.06) improved at epoch 6 | saving best model!
INFO:root:TRAIN | Epoch: [7/20] | Loss: 0.6687 | AP: 49.83 | TP:86.61, FP:118.35, FN:13.02, TN:35.26 | ACC: 48.12
INFO:root:VAL   | Epoch: [7/20] | Loss: 0.7113 | AP: 35.45 | TP:92.5, FP:146.5, FN:36.5, TN:37.5 | ACC: 41.53
INFO:root:=> AP improved (35.45) improved at epoch 7 | saving best model!
INFO:root:TRAIN | Epoch: [8/20] | Loss: 0.6678 | AP: 50.46 | TP:83.23, FP:111.28, FN:16.49, TN:42.24 | ACC: 49.58
INFO:root:VAL   | Epoch: [8/20] | Loss: 0.7109 | AP: 36.05 | TP:96.0, FP:150.5, FN:33.0, TN:33.5 | ACC: 41.37
INFO:root:=> AP improved (36.05) improved at epoch 8 | saving best model!
INFO:root:TRAIN | Epoch: [9/20] | Loss: 0.6675 | AP: 50.67 | TP:85.38, FP:116.77, FN:14.14, TN:36.94 | ACC: 48.35
INFO:root:VAL   | Epoch: [9/20] | Loss: 0.7136 | AP: 36.53 | TP:88.5, FP:143.0, FN:40.5, TN:41.0 | ACC: 41.37
INFO:root:=> AP improved (36.53) improved at epoch 9 | saving best model!
INFO:root:TRAIN | Epoch: [10/20] | Loss: 0.6653 | AP: 51.51 | TP:83.77, FP:112.10, FN:15.88, TN:41.49 | ACC: 49.46
INFO:root:VAL   | Epoch: [10/20] | Loss: 0.7154 | AP: 36.61 | TP:93.0, FP:149.5, FN:36.0, TN:34.5 | ACC: 40.73
INFO:root:=> AP improved (36.61) improved at epoch 10 | saving best model!
INFO:root:TRAIN | Epoch: [11/20] | Loss: 0.6648 | AP: 51.14 | TP:83.88, FP:109.65, FN:15.88, TN:43.82 | ACC: 50.38
INFO:root:VAL   | Epoch: [11/20] | Loss: 0.7175 | AP: 36.51 | TP:91.0, FP:144.5, FN:38.0, TN:39.5 | ACC: 41.69
INFO:root:TRAIN | Epoch: [12/20] | Loss: 0.6637 | AP: 51.29 | TP:83.66, FP:107.63, FN:16.11, TN:45.84 | ACC: 51.09
INFO:root:VAL   | Epoch: [12/20] | Loss: 0.7198 | AP: 37.49 | TP:87.0, FP:140.5, FN:42.0, TN:43.5 | ACC: 41.69
INFO:root:=> AP improved (37.49) improved at epoch 12 | saving best model!
INFO:root:TRAIN | Epoch: [13/20] | Loss: 0.6624 | AP: 51.89 | TP:83.17, FP:108.41, FN:16.47, TN:45.19 | ACC: 50.67
INFO:root:VAL   | Epoch: [13/20] | Loss: 0.7191 | AP: 38.26 | TP:85.5, FP:139.5, FN:43.5, TN:44.5 | ACC: 41.53
INFO:root:=> AP improved (38.26) improved at epoch 13 | saving best model!
INFO:root:TRAIN | Epoch: [14/20] | Loss: 0.6623 | AP: 52.09 | TP:82.36, FP:107.58, FN:17.22, TN:46.07 | ACC: 50.75
INFO:root:VAL   | Epoch: [14/20] | Loss: 0.7216 | AP: 38.35 | TP:82.5, FP:142.0, FN:46.5, TN:42.0 | ACC: 39.78
INFO:root:=> AP improved (38.35) improved at epoch 14 | saving best model!
INFO:root:TRAIN | Epoch: [15/20] | Loss: 0.6624 | AP: 52.19 | TP:82.20, FP:105.37, FN:17.35, TN:48.32 | ACC: 51.57
INFO:root:VAL   | Epoch: [15/20] | Loss: 0.7296 | AP: 36.82 | TP:85.0, FP:146.5, FN:44.0, TN:37.5 | ACC: 39.14
INFO:root:TRAIN | Epoch: [16/20] | Loss: 0.6608 | AP: 52.63 | TP:82.03, FP:104.22, FN:17.59, TN:49.40 | ACC: 51.92
INFO:root:VAL   | Epoch: [16/20] | Loss: 0.7310 | AP: 37.10 | TP:84.5, FP:142.0, FN:44.5, TN:42.0 | ACC: 40.42
INFO:root:TRAIN | Epoch: [17/20] | Loss: 0.6609 | AP: 52.57 | TP:83.34, FP:106.92, FN:16.25, TN:46.73 | ACC: 51.34
INFO:root:VAL   | Epoch: [17/20] | Loss: 0.7336 | AP: 37.80 | TP:79.0, FP:132.0, FN:50.0, TN:52.0 | ACC: 41.85
INFO:root:TRAIN | Epoch: [18/20] | Loss: 0.6604 | AP: 52.77 | TP:82.51, FP:104.98, FN:17.17, TN:48.59 | ACC: 51.84
INFO:root:VAL   | Epoch: [18/20] | Loss: 0.7359 | AP: 37.04 | TP:80.5, FP:140.0, FN:48.5, TN:44.0 | ACC: 39.78
INFO:root:TRAIN | Epoch: [19/20] | Loss: 0.6610 | AP: 52.60 | TP:80.57, FP:101.67, FN:19.20, TN:51.79 | ACC: 52.23
INFO:root:VAL   | Epoch: [19/20] | Loss: 0.7357 | AP: 37.27 | TP:85.0, FP:144.0, FN:44.0, TN:40.0 | ACC: 39.94
INFO:root:### Training from epoch 0 -> 19 finished in (29.48) minutes
INFO:root:### Best validation AP: 38.35 in epoch 14
INFO:root:# Test Set | Loss: 0.6936 | AP: 42.78 | TP:194.0, FP:276.0, FN:43.0, TN:70.0 | ACC: 45.28
INFO:root:Namespace(aggregation='average', batch_size=256, debug=False, device=device(type='cpu'), dropout=0.1, epochs=30, hidden_size=128, in_features=17, kernel_size=3, log_dir='exps/logs', lr=0.0001, model='GRU', num_channels=[64, 64, 128], num_classes=2, num_layers=2, num_workers=4, print_freq=5, root='data', save_dir='exps/chpts/GRU_layers2_stride5_average_lr0.0001', seed=14, start_epoch=0, tb_dir='exps/tb/GRU_layers2_stride5_average_lr0.0001', temp_stride=5, wd=1e-05)
INFO:root:GRU(
  (rnn): GRU(17, 128, num_layers=2, batch_first=True)
  (fc): Linear(in_features=128, out_features=2, bias=True)
  (avg_pool): AdaptiveAvgPool1d(output_size=1)
  (max_pool): AdaptiveMaxPool1d(output_size=1)
)
INFO:root:=> Loading 4792 samples for train
INFO:root:=> Loading 626 samples for val
INFO:root:=> Loading 1166 samples for test
INFO:root:TRAIN | Epoch: [0/30] | Loss: 0.6888 | AP: 41.35 | TP:90.90, FP:142.63, FN:8.76, TN:10.95 | ACC: 40.21
INFO:root:VAL   | Epoch: [0/30] | Loss: 0.6942 | AP: 30.50 | TP:129.0, FP:184.0, FN:0.0, TN:0.0 | ACC: 41.21
INFO:root:=> AP improved (30.50) improved at epoch 0 | saving best model!
INFO:root:TRAIN | Epoch: [1/30] | Loss: 0.6818 | AP: 45.06 | TP:99.46, FP:152.92, FN:0.32, TN:0.53 | ACC: 39.44
INFO:root:VAL   | Epoch: [1/30] | Loss: 0.6964 | AP: 31.71 | TP:128.0, FP:182.0, FN:1.0, TN:2.0 | ACC: 41.53
INFO:root:=> AP improved (31.71) improved at epoch 1 | saving best model!
INFO:root:TRAIN | Epoch: [2/30] | Loss: 0.6785 | AP: 47.37 | TP:96.29, FP:144.78, FN:3.41, TN:8.76 | ACC: 41.49
INFO:root:VAL   | Epoch: [2/30] | Loss: 0.6988 | AP: 33.16 | TP:116.0, FP:167.5, FN:13.0, TN:16.5 | ACC: 42.33
INFO:root:=> AP improved (33.16) improved at epoch 2 | saving best model!
INFO:root:TRAIN | Epoch: [3/30] | Loss: 0.6753 | AP: 48.37 | TP:92.02, FP:132.43, FN:7.61, TN:21.17 | ACC: 44.68
INFO:root:VAL   | Epoch: [3/30] | Loss: 0.7040 | AP: 33.34 | TP:113.0, FP:161.0, FN:16.0, TN:23.0 | ACC: 43.45
INFO:root:=> AP improved (33.34) improved at epoch 3 | saving best model!
INFO:root:TRAIN | Epoch: [4/30] | Loss: 0.6738 | AP: 48.52 | TP:90.70, FP:129.81, FN:9.00, TN:23.72 | ACC: 45.14
INFO:root:VAL   | Epoch: [4/30] | Loss: 0.7052 | AP: 33.91 | TP:109.5, FP:161.5, FN:19.5, TN:22.5 | ACC: 42.17
INFO:root:=> AP improved (33.91) improved at epoch 4 | saving best model!
INFO:root:TRAIN | Epoch: [5/30] | Loss: 0.6718 | AP: 48.95 | TP:88.19, FP:123.00, FN:11.48, TN:30.56 | ACC: 46.91
INFO:root:VAL   | Epoch: [5/30] | Loss: 0.7069 | AP: 34.70 | TP:100.5, FP:155.0, FN:28.5, TN:29.0 | ACC: 41.37
INFO:root:=> AP improved (34.70) improved at epoch 5 | saving best model!
INFO:root:TRAIN | Epoch: [6/30] | Loss: 0.6701 | AP: 49.28 | TP:85.66, FP:116.51, FN:14.13, TN:36.93 | ACC: 48.33
INFO:root:VAL   | Epoch: [6/30] | Loss: 0.7105 | AP: 34.68 | TP:103.5, FP:159.0, FN:25.5, TN:25.0 | ACC: 41.05
INFO:root:TRAIN | Epoch: [7/30] | Loss: 0.6693 | AP: 50.01 | TP:86.52, FP:119.34, FN:13.11, TN:34.26 | ACC: 47.66
INFO:root:VAL   | Epoch: [7/30] | Loss: 0.7112 | AP: 35.78 | TP:95.0, FP:144.0, FN:34.0, TN:40.0 | ACC: 43.13
INFO:root:=> AP improved (35.78) improved at epoch 7 | saving best model!
INFO:root:TRAIN | Epoch: [8/30] | Loss: 0.6682 | AP: 50.12 | TP:82.61, FP:111.34, FN:17.11, TN:42.18 | ACC: 49.29
INFO:root:VAL   | Epoch: [8/30] | Loss: 0.7119 | AP: 35.86 | TP:96.5, FP:150.0, FN:32.5, TN:34.0 | ACC: 41.69
INFO:root:=> AP improved (35.86) improved at epoch 8 | saving best model!
INFO:root:TRAIN | Epoch: [9/30] | Loss: 0.6670 | AP: 50.58 | TP:85.50, FP:117.28, FN:14.02, TN:36.43 | ACC: 48.21
INFO:root:VAL   | Epoch: [9/30] | Loss: 0.7134 | AP: 36.31 | TP:89.5, FP:143.0, FN:39.5, TN:41.0 | ACC: 41.69
INFO:root:=> AP improved (36.31) improved at epoch 9 | saving best model!
INFO:root:TRAIN | Epoch: [10/30] | Loss: 0.6659 | AP: 51.04 | TP:84.26, FP:112.15, FN:15.38, TN:41.44 | ACC: 49.62
INFO:root:VAL   | Epoch: [10/30] | Loss: 0.7142 | AP: 36.48 | TP:95.0, FP:150.5, FN:34.0, TN:33.5 | ACC: 41.05
INFO:root:=> AP improved (36.48) improved at epoch 10 | saving best model!
INFO:root:TRAIN | Epoch: [11/30] | Loss: 0.6647 | AP: 51.53 | TP:84.24, FP:110.59, FN:15.53, TN:42.88 | ACC: 50.17
INFO:root:VAL   | Epoch: [11/30] | Loss: 0.7174 | AP: 36.61 | TP:91.0, FP:148.0, FN:38.0, TN:36.0 | ACC: 40.58
INFO:root:=> AP improved (36.61) improved at epoch 11 | saving best model!
INFO:root:TRAIN | Epoch: [12/30] | Loss: 0.6643 | AP: 51.34 | TP:83.46, FP:108.84, FN:16.31, TN:44.63 | ACC: 50.52
INFO:root:VAL   | Epoch: [12/30] | Loss: 0.7192 | AP: 36.91 | TP:85.5, FP:143.0, FN:43.5, TN:41.0 | ACC: 40.42
INFO:root:=> AP improved (36.91) improved at epoch 12 | saving best model!
INFO:root:TRAIN | Epoch: [13/30] | Loss: 0.6638 | AP: 51.45 | TP:84.68, FP:110.22, FN:14.96, TN:43.38 | ACC: 50.52
INFO:root:VAL   | Epoch: [13/30] | Loss: 0.7214 | AP: 37.99 | TP:84.0, FP:140.0, FN:45.0, TN:44.0 | ACC: 40.89
INFO:root:=> AP improved (37.99) improved at epoch 13 | saving best model!
INFO:root:TRAIN | Epoch: [14/30] | Loss: 0.6618 | AP: 52.21 | TP:83.19, FP:107.13, FN:16.40, TN:46.52 | ACC: 51.27
INFO:root:VAL   | Epoch: [14/30] | Loss: 0.7238 | AP: 37.49 | TP:84.0, FP:141.5, FN:45.0, TN:42.5 | ACC: 40.42
INFO:root:TRAIN | Epoch: [15/30] | Loss: 0.6621 | AP: 52.11 | TP:81.80, FP:105.03, FN:17.75, TN:48.65 | ACC: 51.54
INFO:root:VAL   | Epoch: [15/30] | Loss: 0.7309 | AP: 36.63 | TP:83.0, FP:145.0, FN:46.0, TN:39.0 | ACC: 38.98
INFO:root:TRAIN | Epoch: [16/30] | Loss: 0.6623 | AP: 52.13 | TP:81.66, FP:104.46, FN:17.95, TN:49.17 | ACC: 51.69
INFO:root:VAL   | Epoch: [16/30] | Loss: 0.7351 | AP: 36.43 | TP:82.0, FP:142.0, FN:47.0, TN:42.0 | ACC: 39.62
INFO:root:TRAIN | Epoch: [17/30] | Loss: 0.6601 | AP: 52.60 | TP:83.70, FP:108.40, FN:15.89, TN:45.25 | ACC: 50.90
INFO:root:VAL   | Epoch: [17/30] | Loss: 0.7324 | AP: 37.36 | TP:77.5, FP:134.0, FN:51.5, TN:50.0 | ACC: 40.73
INFO:root:TRAIN | Epoch: [18/30] | Loss: 0.6624 | AP: 52.38 | TP:82.12, FP:105.95, FN:17.55, TN:47.62 | ACC: 51.29
INFO:root:VAL   | Epoch: [18/30] | Loss: 0.7300 | AP: 37.04 | TP:84.0, FP:144.0, FN:45.0, TN:40.0 | ACC: 39.62
INFO:root:TRAIN | Epoch: [19/30] | Loss: 0.6623 | AP: 52.45 | TP:80.45, FP:103.55, FN:19.33, TN:49.90 | ACC: 51.46
INFO:root:VAL   | Epoch: [19/30] | Loss: 0.7333 | AP: 36.87 | TP:86.0, FP:148.5, FN:43.0, TN:35.5 | ACC: 38.82
INFO:root:TRAIN | Epoch: [20/30] | Loss: 0.6614 | AP: 52.70 | TP:80.41, FP:102.13, FN:19.27, TN:51.44 | ACC: 52.02
INFO:root:VAL   | Epoch: [20/30] | Loss: 0.7389 | AP: 36.61 | TP:83.0, FP:141.5, FN:46.0, TN:42.5 | ACC: 40.10
INFO:root:TRAIN | Epoch: [21/30] | Loss: 0.6592 | AP: 52.93 | TP:81.28, FP:104.43, FN:18.29, TN:49.24 | ACC: 51.57
INFO:root:VAL   | Epoch: [21/30] | Loss: 0.7415 | AP: 37.02 | TP:80.0, FP:136.0, FN:49.0, TN:48.0 | ACC: 40.89
INFO:root:TRAIN | Epoch: [22/30] | Loss: 0.6582 | AP: 53.37 | TP:81.10, FP:102.62, FN:18.48, TN:51.03 | ACC: 52.19
INFO:root:VAL   | Epoch: [22/30] | Loss: 0.7419 | AP: 36.93 | TP:79.0, FP:139.5, FN:50.0, TN:44.5 | ACC: 39.46
INFO:root:TRAIN | Epoch: [23/30] | Loss: 0.6597 | AP: 53.37 | TP:78.53, FP:98.53, FN:20.91, TN:55.27 | ACC: 52.88
INFO:root:VAL   | Epoch: [23/30] | Loss: 0.7496 | AP: 36.45 | TP:84.0, FP:150.5, FN:45.0, TN:33.5 | ACC: 37.54
INFO:root:TRAIN | Epoch: [24/30] | Loss: 0.6592 | AP: 53.35 | TP:82.94, FP:105.82, FN:16.85, TN:47.62 | ACC: 51.48
INFO:root:VAL   | Epoch: [24/30] | Loss: 0.7450 | AP: 37.44 | TP:74.5, FP:130.0, FN:54.5, TN:54.0 | ACC: 41.05
INFO:root:TRAIN | Epoch: [25/30] | Loss: 0.6581 | AP: 53.51 | TP:78.23, FP:96.70, FN:21.40, TN:56.90 | ACC: 53.34
INFO:root:VAL   | Epoch: [25/30] | Loss: 0.7521 | AP: 37.33 | TP:82.0, FP:141.0, FN:47.0, TN:43.0 | ACC: 39.94
INFO:root:TRAIN | Epoch: [26/30] | Loss: 0.6577 | AP: 53.75 | TP:78.72, FP:97.30, FN:20.77, TN:56.44 | ACC: 53.44
INFO:root:VAL   | Epoch: [26/30] | Loss: 0.7436 | AP: 37.61 | TP:78.5, FP:132.5, FN:50.5, TN:51.5 | ACC: 41.53
INFO:root:TRAIN | Epoch: [27/30] | Loss: 0.6564 | AP: 54.27 | TP:80.63, FP:100.73, FN:19.14, TN:52.75 | ACC: 52.65
INFO:root:VAL   | Epoch: [27/30] | Loss: 0.7528 | AP: 37.49 | TP:77.5, FP:131.5, FN:51.5, TN:52.5 | ACC: 41.53
INFO:root:TRAIN | Epoch: [28/30] | Loss: 0.6555 | AP: 54.37 | TP:79.69, FP:98.46, FN:20.05, TN:55.04 | ACC: 53.19
INFO:root:VAL   | Epoch: [28/30] | Loss: 0.7466 | AP: 38.05 | TP:77.0, FP:127.0, FN:52.0, TN:57.0 | ACC: 42.81
INFO:root:=> AP improved (38.05) improved at epoch 28 | saving best model!
INFO:root:TRAIN | Epoch: [29/30] | Loss: 0.6552 | AP: 54.52 | TP:79.71, FP:97.72, FN:19.96, TN:55.84 | ACC: 53.53
INFO:root:VAL   | Epoch: [29/30] | Loss: 0.7488 | AP: 39.10 | TP:74.5, FP:119.5, FN:54.5, TN:64.5 | ACC: 44.41
INFO:root:=> AP improved (39.10) improved at epoch 29 | saving best model!
INFO:root:### Training from epoch 0 -> 29 finished in (24.84) minutes
INFO:root:### Best validation AP: 39.10 in epoch 29
INFO:root:# Test Set | Loss: 0.7220 | AP: 40.73 | TP:167.5, FP:230.5, FN:69.5, TN:115.5 | ACC: 48.54
INFO:root:Namespace(aggregation='average', batch_size=256, debug=False, device=device(type='cpu'), dropout=0.1, epochs=30, hidden_size=128, in_features=17, kernel_size=3, log_dir='exps/logs', lr=0.0001, model='GRU', num_channels=[64, 64, 128], num_classes=2, num_layers=2, num_workers=4, print_freq=5, root='data', save_dir='exps/chpts/GRU_layers2_stride5_average_lr0.0001', seed=14, start_epoch=0, tb_dir='exps/tb/GRU_layers2_stride5_average_lr0.0001', temp_stride=5, wd=1e-05)
INFO:root:GRU(
  (rnn): GRU(17, 128, num_layers=2, batch_first=True)
  (fc): Linear(in_features=128, out_features=2, bias=True)
  (avg_pool): AdaptiveAvgPool1d(output_size=1)
  (max_pool): AdaptiveMaxPool1d(output_size=1)
)
INFO:root:=> Loading 2396 samples for train
INFO:root:=> Loading 313 samples for val
INFO:root:=> Loading 583 samples for test
INFO:root:TRAIN | Epoch: [0/30] | Loss: 0.6901 | AP: 41.05 | TP:81.16, FP:124.38, FN:17.13, TN:27.03 | ACC: 43.20
INFO:root:VAL   | Epoch: [0/30] | Loss: 0.6945 | AP: 30.29 | TP:129.0, FP:184.0, FN:0.0, TN:0.0 | ACC: 41.21
INFO:root:=> AP improved (30.29) improved at epoch 0 | saving best model!
